# reinforcement


Here is the note of RL class.

Hw1: Rabbit farm.
<br>To make you be familiar with python and its libraries.<br/>

Hw2: Value Function using matrix approach. 
<br>Numpy is a good tools for solving matrix computing problems.<br/>

Hw3: Value Function & optimal policy using iterative DP method.
<br>Getting to know more about RL with "Values" & "Policy".<br/>

Hw4: Monte Carlo with Cat-Mouse environment. 
<br>Testing environments with Cat-Mouse envs with our First real RL method "Monte Carlo".<br/>

Hw5: Q-Learning with Cat-Mouse env. 
<br>A "model free" method, computing "Q(S,A)" without building the States as last homework.<br/>

Hw6: Sarsa & Expected Sarsa with epsilon greedy policy. 
<br>Sarsa is a little bit more conservative strategy with more exploring state while implementing "Epsilon Decay".<br/>

Hw7: Pytorch & CNN. 
<br>An overview with CNN models & pytorch API.<br/>

Hw8: Semi-gradient TD(0) with NN function approximation. 
<br>Cat-Mouse env again! Learning our "Values" & "Policy" with NN model. Interesting.<br/>

Hw9: Q-Learning with NN && Acrobot environment. 
<br>Off-policy Q-Learning sometimes causes "Dead Triad". How do we solve it?<br/>

Hw10: Policy gradient using REINFORCE method
<br>Acrobot & CartPole envs with policy gradient method. We directly derive our poloicy rather than using V(s) or Q(s,a).<br/>


